{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PhoPQ Activation Model\n",
    "\n",
    "Kenny Groszman, in collaboration with Kathryn Brink of Rice University Department of Bioengineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we produce a model that predicts PhoPQ activation by cathelicidin-like peptides, based on a set of autoatically generated physical features from a library of peptides\n",
    "\n",
    "The model is structured as follows:\n",
    "\n",
    "- **Data import and cleaning**\n",
    "    - Determine closest parent human AMP for each candidate sequence\n",
    "    - Filter out peptides with no human AMP parent based on longest contiguous subsequence\n",
    "    - Create a dataset with only cathelicidin-like (LL37-like) peptides\n",
    "- **Feature selection**\n",
    "    - Remove redundant and unnecessary features from the dataset\n",
    "- **Model generation**\n",
    "    - Cross-validate hyperparameters for a sparse and robust linear model\n",
    "    - Validate results on holdout set\n",
    "- **Create and save relevant outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inport packages and add processing power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Plots, Statistics, JLD2, Distributed, Random, PyCall, ScikitLearn\n",
    "@sk_import model_selection: ShuffleSplit;\n",
    "addprocs(4) #add processing power\n",
    "IJulia.clear_output();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia version: `1.5.3`\n",
    "\n",
    "Julia packages used:\n",
    "\n",
    "- For file reading and writing: [`CSV @v0.8.3`](https://csv.juliadata.org/stable/)\n",
    "- For data manipulation:  [`DataFrames @v0.22.1`](https://dataframes.juliadata.org/stable/)\n",
    "- For data visualization: [`Plots @v1.10.5`](http://docs.juliaplots.org/latest/)\n",
    "- For basic statistical functions (e.g., correlation): [`Statistics @v1.5`](https://docs.julialang.org/en/v1/stdlib/Statistics/)\n",
    "- For saving and loading Julia objects: [`JLD2 @v0.4.1`](https://github.com/JuliaIO/JLD2.jl)\n",
    "- For distributed computing: [`Distributed @v1.5`](https://docs.julialang.org/en/v1/manual/distributed-computing/)\n",
    "- For access to random variables and permutations: [`Random @v1.5`](https://docs.julialang.org/en/v1/stdlib/Random/)\n",
    "- For interpretable machine learning algorithms: [`Interpretable AI @v2.1.0`](https://docs.interpretable.ai/stable/)\n",
    "- For shuffled cross validation: [`ScikitLearn @v0.6.3`](https://scikitlearnjl.readthedocs.io/en/latest/)\n",
    "- For accessing Python-based functions (e.g., SKLearn): [`PyCall @v1.92.2`](https://github.com/JuliaPy/PyCall.jl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning\n",
    "\n",
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe\n",
    "df = CSV.read(\"data/peptide_features.tsv\", delim='\\t', DataFrame);\n",
    "\n",
    "rename!(df, :Column1 => :Sequence); #rename sequence column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"DF: \", size(df))\n",
    "n_seq = size(df)[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import human AMP parent sequences\n",
    "\n",
    "parent_df = CSV.read(\"data/peptides_df_clustered.csv\", DataFrame);\n",
    "\n",
    "println(\"Parent DF: \", size(parent_df))\n",
    "n_parents = size(parent_df)[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find parent sequence with longest contiguous subsequence for each peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# define function for longest contiguous subsequence\n",
    "###\n",
    "\n",
    "# Source: https://github.com/WestleyArgentum/Subsequences.jl\n",
    "\n",
    "function longest_contiguous_subsequence(a, b)\n",
    "    m = zeros(Int, length(a) + 1, length(b) + 1)\n",
    "    longest, x_longest, y_longest = 0, 0, 0\n",
    "\n",
    "    for x in 2:(length(a) + 1)\n",
    "        for y in 2:(length(b) + 1)\n",
    "\n",
    "            if a[x - 1] == b[y - 1]\n",
    "                m[x, y] = m[x - 1, y - 1] + 1\n",
    "\n",
    "                if m[x, y] > longest\n",
    "                    longest = m[x, y]\n",
    "                    x_longest = x\n",
    "                    y_longest = y\n",
    "                end\n",
    "            else\n",
    "                m[x, y] = 0\n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "\n",
    "    a_range = (x_longest - longest):(x_longest - 1)\n",
    "    b_range = (y_longest - longest):(y_longest - 1)\n",
    "    a[a_range], a_range, b_range\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Find the closest human AMP parent for each peptide\n",
    "###\n",
    "\n",
    "# initialize output arrays\n",
    "seq_parent = []\n",
    "seq_parent_cluster = zeros(n_seq)\n",
    "seq_parent_lcs = zeros(n_seq)\n",
    "\n",
    "\n",
    "s=0\n",
    "\n",
    "for i in eachrow(df)\n",
    "    s=s+1\n",
    "\n",
    "    lcs_array = zeros(n_parents)\n",
    "    c = 1\n",
    "    \n",
    "    seq_len = length(i[:Sequence])\n",
    "    \n",
    "    for p in eachrow(parent_df)\n",
    "        lcs_array[c] = length(longest_contiguous_subsequence(i[:Sequence], p[:Sequence])[1])\n",
    "        c=c+1\n",
    "    end\n",
    "    \n",
    "    i_max_match = argmax(lcs_array)\n",
    "    \n",
    "    seq_parent_lcs[s] = lcs_array[i_max_match]\n",
    "    push!(seq_parent, parent_df[i_max_match, :Sequence])\n",
    "    seq_parent_cluster[s] = parent_df[i_max_match, :Cluster]\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create df_matched table with original features and new LCS / parents columns\n",
    "###\n",
    "\n",
    "df_matched = deepcopy(df)\n",
    "\n",
    "df_matched.Parent_Sequence = seq_parent\n",
    "df_matched.Parent_Cluster = seq_parent_cluster\n",
    "df_matched.LCS = seq_parent_lcs\n",
    "\n",
    "println(\"DF Size: \", size(df))\n",
    "println(\"DF Matched Size: \", size(df_matched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = deepcopy(seq_parent_lcs)\n",
    "sort!(match)\n",
    "plot(match, legend=false, size = (700, 300), xlabel = \"sequence index\", ylabel = \"Length, Largest Contiguous Subsequence\")\n",
    "plot!(ones(size(match))*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#Set threshold for minimum common subset to be considered a match\n",
    "###\n",
    "\n",
    "LCS_threshold = 7 # match must be at least 7 contiguous sequences to be considered a match\n",
    "\n",
    "\n",
    "df_matched.Is_Matched = map(eachrow(df_matched)) do r\n",
    "    if r.LCS >= LCS_threshold\n",
    "        return 1\n",
    "    else\n",
    "        0\n",
    "    end\n",
    "end\n",
    "\n",
    "df_matched.Adj_Cluster = map(eachrow(df_matched)) do r\n",
    "    if r.Is_Matched == 1\n",
    "        return Int(r.Parent_Cluster)\n",
    "    else\n",
    "        -999 #label column with cluster -999 if no match\n",
    "    end\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize  # of peptides per cluster\n",
    "\n",
    "first(sort(combine(groupby(df_matched, :Adj_Cluster), nrow), :nrow, rev=true), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output sequences and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Output df to sanity check\n",
    "###\n",
    "\n",
    "output_df = select(df_matched, [:Sequence, :Parent_Sequence, :LCS, :Parent_Cluster, :Adj_Cluster]);\n",
    "\n",
    "CSV.write(\"clustering_results_vF.csv\", output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset with all sequences and clusters\n",
    "\n",
    "Note: Although we will ultimately build a model just for LL-37-like AMPs, we prepare a dataset that includes all clusters since we will use this to validate the generalizability of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Prepare data for model by doing the following:\n",
    "# 0. Remove rows with no matching cluster\n",
    "# 1. Split into X and Y (and remove superfluous columns)\n",
    "# 2. Split into Train and Test\n",
    "###\n",
    "\n",
    "\n",
    "df_model = deepcopy(df_matched) # size: (3495, 1291)\n",
    "\n",
    "# Filter -999 cluster\n",
    "df_full = filter(row -> row.Adj_Cluster != -999 , df_model ); # size: (2747, 1291) \n",
    "\n",
    "# Remove superfluous columns and separate columns into X and Y\n",
    "X_full = select(df_full, Not([:FoldChange, :Parent_Cluster, :Parent_Sequence]));\n",
    "Y_full = Array{Float64}(df_full.FoldChange);\n",
    "\n",
    "size(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create dataset with just LL-37-like sequences\n",
    "### \n",
    "\n",
    "#filter out just LL-37 cluster (cluster 5)\n",
    "df_LL37 =  filter(row -> row.Adj_Cluster == 5 , df_model ); # (410, 1291)\n",
    "\n",
    "# Remove superfluous columns and separate columns into X and Y\n",
    "X_LL37 = select(df_LL37, Not([:FoldChange, :Parent_Cluster, :Parent_Sequence])); # size: (410, 1288) \n",
    "Y_LL37 = Array{Float64}(df_LL37.FoldChange); #size (410,)\n",
    "\n",
    "println(\"Size of X_LL37: \", size(X_LL37))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test\n",
    "(cv_X, cv_y), (test_X, test_y) = IAI.split_data(:regression, X_LL37, Y_LL37, train_proportion=.75);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create a dataframe to track dropped columns\n",
    "###\n",
    "\n",
    "dropped_columns_hist = DataFrame(\n",
    "    ColumnName = Symbol[],\n",
    "    Reason_Dropped = String[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create helper function to be used throughout feature selection and model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Define helper functions to be used theoughout\n",
    "###\n",
    "\n",
    "function get_ready_X(X)\n",
    "    ### Function to remove columns from X dataframe which are not to be used for modeling\n",
    "    \n",
    "    del_cols = [:Sequence, :LCS, :Adj_Cluster, :Is_Matched]\n",
    "    X2 = select(X, Not(del_cols))\n",
    "    return X2\n",
    "end\n",
    "\n",
    "\n",
    "function get_log_y(y)\n",
    "    ### Function to process response variable for running model\n",
    "    \n",
    "    return log10.(y)\n",
    "end\n",
    "\n",
    "function get_r2(real_y, predict_y)\n",
    "    ### Calcualte r2 validation metric\n",
    "    \n",
    "    ssr = sum((predict_y .- real_y).^2)\n",
    "    sst = sum((real_y .- mean(real_y)).^2)\n",
    "    return 1 - ssr/sst\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any features with zero variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_X_f1 = deepcopy(cv_X) # make the first filtered version of cv_X\n",
    "\n",
    "colnames = propertynames(cv_X)\n",
    "\n",
    "drop_cols = []\n",
    "\n",
    "for i = 1:length(colnames)\n",
    "    if colnames[i] ∉ [:Sequence, :LCS, :Is_Matched, :Adj_Cluster]\n",
    "        col_variance = Statistics.var(cv_X[:,colnames[i]])\n",
    "        \n",
    "        if col_variance < 0.000001\n",
    "            println(\"Column $(colnames[i]) has variance of $col_variance. Removing from dataset.\")\n",
    "            push!(drop_cols, colnames[i])\n",
    "        end\n",
    "        \n",
    "    end\n",
    "end\n",
    "\n",
    "cv_X_f1 = select(cv_X_f1, Not(drop_cols)) #filter out columns with zero variance\n",
    "\n",
    "\n",
    "println(\"\\nSize of cv_X: \", size(cv_X))\n",
    "println(\"Size of cv_X_f1: \", size(cv_X_f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append removed columns into dropped columns dataframe\n",
    "\n",
    "for i = 1 : length(drop_cols)\n",
    "    push!(dropped_columns_hist, [drop_cols[i], \"Zero Variance\"])\n",
    "end\n",
    "\n",
    "dropped_columns_hist;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove pairwise correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function remove_pairwise_correlated_columns(X::DataFrame, y, ρ_max)\n",
    "    # return X2 DF without any pairwise correlated columns. Keep column with best relation to y\n",
    "    \n",
    "    X2 = deepcopy(X)\n",
    "    drop_col_list = []\n",
    "    drop_col_reason = []\n",
    "\n",
    "    function get_cor_X(X)\n",
    "        cor_X = cor(Matrix(X));\n",
    "        \n",
    "        for i = 1:size(cor_X)[1]\n",
    "           cor_X[i,i] = 0 \n",
    "        end\n",
    "        return cor_X\n",
    "    end\n",
    "    \n",
    "    function get_cor_y(X2, y)\n",
    "        #correlation of each feature with y\n",
    "        cor_y = []\n",
    "        for i = 1 : size(X2)[2]\n",
    "            push!(cor_y, cor(X2[:,i], y))\n",
    "        end\n",
    "        return cor_y\n",
    "    end\n",
    "    \n",
    "    \n",
    "    loop_flag = true\n",
    "    \n",
    "    while loop_flag\n",
    "        \n",
    "        # get latest matrices\n",
    "        cor_X = get_cor_X(X2)\n",
    "        cor_y = get_cor_y(X2, y)\n",
    "        colnames = propertynames(X2)\n",
    "       \n",
    "        # Get the highest correlated pair\n",
    "        max_pair = argmax(abs.(cor_X))\n",
    "        i, j = max_pair[1], max_pair[2]\n",
    "        println(\"--------\")\n",
    "        println(\"Found matching pair: $(colnames[i]) and $(colnames[j]) with ρ = $(cor_X[i,j])\")\n",
    "        \n",
    "        \n",
    "        if abs.(cor_X[i,j]) >= ρ_max\n",
    "            \n",
    "            # pick which column to drop based on absolute value of corrlation\n",
    "            if abs(cor_y[j]) < abs(cor_y[i])\n",
    "                drop_col = colnames[j]\n",
    "            else\n",
    "                drop_col = colnames[i]\n",
    "            end\n",
    "            println(\"Column $(colnames[i]) has y-corr $(cor_y[i])\")\n",
    "            println(\"Column $(colnames[j]) has y-corr $(cor_y[j])\")\n",
    "            println(\"Dropping column $drop_col \")\n",
    "\n",
    "            # drop column\n",
    "            X2 = select(X2, Not(drop_col))\n",
    "            push!(drop_col_list, drop_col)\n",
    "            push!(drop_col_reason, \"Pairwise ρ = $(cor_X[i,j]) between $(colnames[i]) and $(colnames[j])\")\n",
    "\n",
    "        else #EXIT LOOP\n",
    "            loop_flag = false\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return X2, drop_col_list, drop_col_reason\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Run function to remove pairwise correlated columns of X\n",
    "###\n",
    "\n",
    "\n",
    "ρ_max = 0.95\n",
    "\n",
    "~, f2_drop_cols, f2_drop_cols_reason = remove_pairwise_correlated_columns(get_ready_X(cv_X_f1), get_log_y(cv_y), ρ_max);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append into dropped columns dataframe\n",
    "for i = 1 : length(f2_drop_cols)\n",
    "    push!(dropped_columns_hist, [f2_drop_cols[i], f2_drop_cols_reason[i]])\n",
    "end\n",
    "\n",
    "dropped_columns_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply dropped columns from second filtering step\n",
    "cv_X_f2 = deepcopy(cv_X_f1)\n",
    "cv_X_f2 = select(cv_X_f2, Not(f2_drop_cols)); #size: (308, 988)\n",
    "size(cv_X_f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sparse and Robust Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes makes sense\n",
    "size(cv_X_f2) #size: (308, 979)\n",
    "size(cv_y) # size 308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sparsity_cross_validation(k_vals, γ_vals, folds, cv_X, cv_y)\n",
    "    ### Function to run shuffled cross validation for various values of sparsity (k) and regularizaition (γ)\n",
    "    ### Return the parameters for the best model\n",
    "\n",
    "\n",
    "    fold_hist = []\n",
    "    k_hist = []\n",
    "    γ_hist = []\n",
    "    train_mse_hist = []\n",
    "    valid_mse_hist = []\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    scv = ShuffleSplit(n_splits = folds, test_size = 0.25)\n",
    "\n",
    "    for (train, validation) in scv.split(Matrix(get_ready_X(cv_X)), get_log_y(cv_y))\n",
    "        fold = fold + 1\n",
    "\n",
    "        # adjust train  / validation indexing to work with Julia (idx starting at 1) \n",
    "        train_idx = train .+ 1\n",
    "        validation_idx = validation .+ 1\n",
    "\n",
    "        for i = 1:length(k_vals), j = 1:length(γ_vals)\n",
    "\n",
    "            #train model on fold with selected sparsity\n",
    "            lnr = IAI.OptimalFeatureSelectionRegressor(sparsity = k_vals[i], gamma = γ_vals[j])\n",
    "            IAI.fit!(lnr, get_ready_X(cv_X)[train_idx,:], get_log_y(cv_y)[train_idx] )\n",
    "\n",
    "            # store results\n",
    "            push!(fold_hist, fold)\n",
    "            push!(k_hist, k_vals[i])\n",
    "            push!(γ_hist, γ_vals[j])\n",
    "            push!(train_mse_hist, IAI.score(lnr, get_ready_X(cv_X)[train_idx,:], get_log_y(cv_y)[train_idx], criterion = :mse))\n",
    "            push!(valid_mse_hist,  IAI.score(lnr, get_ready_X(cv_X)[validation_idx,:], get_log_y(cv_y)[validation_idx], criterion = :mse))\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    grid_search_result = DataFrame(\n",
    "        :Fold => fold_hist, \n",
    "        :k => k_hist,\n",
    "        :γ => γ_hist,\n",
    "        :Train_MSE => train_mse_hist,\n",
    "        :Valid_MSE => valid_mse_hist,\n",
    "    )\n",
    "\n",
    "    cross_val_summary = combine(groupby(grid_search_result, [:k, :γ]), \n",
    "        :Train_MSE => mean => :Avg_Train_MSE,\n",
    "        :Train_MSE => std => :SD_Train_MSE,\n",
    "        :Valid_MSE => mean => :Avg_Valid_MSE,\n",
    "        :Valid_MSE => std => :SD_Valid_MSE,\n",
    ")\n",
    "    \n",
    "    best_k_idx = argmax(cross_val_summary[:,:Avg_Valid_MSE])\n",
    "    \n",
    "    best_k = cross_val_summary[best_k_idx, :k]\n",
    "\n",
    "    return cross_val_summary, grid_search_result, best_k\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters for hyperparameter tuning\n",
    "k_vals = 1:10:401;\n",
    "γ_vals = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "folds = 15;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df, detailed_results, best_k = sparsity_cross_validation(k_vals, γ_vals, folds, cv_X_f2, cv_y)\n",
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = length(γ_vals)\n",
    "colors = reshape( range(colorant\"lightgray\", stop=colorant\"darkblue\",length=n), 1, n );\n",
    "p = plot(xlabel = \"Sparsity (k)\", ylabel  = \"Mean, Validation r²\", legend = :outerright, ylim = [0,1], title = \"Coarse Search Results\")\n",
    "\n",
    "\n",
    "for i = 1:length(γ_vals)\n",
    "    temp_df = filter(row -> row.γ == γ_vals[i], grid_df)\n",
    "    if  γ_vals[i] == 0.005\n",
    "        p = plot!(temp_df.k, temp_df.Avg_Valid_MSE, label = \"γ = $( γ_vals[i])\", linecolor = :red)\n",
    "    else\n",
    "        p = plot!(temp_df.k, temp_df.Avg_Valid_MSE, label = \"γ = $( γ_vals[i])\", linecolor = colors[i])\n",
    "    end\n",
    "        \n",
    "end\n",
    "\n",
    "q = plot(xlabel = \"Sparsity (k)\", ylabel  = \"SD, Validation r²\", legend = :outerright)\n",
    "for i = 1:length(γ_vals)\n",
    "    temp_df = filter(row -> row.γ == γ_vals[i], grid_df)\n",
    "    if  γ_vals[i] == 0.005\n",
    "        q = plot!(temp_df.k, temp_df.SD_Valid_MSE, label = \"γ = $( γ_vals[i])\", linecolor = :red)\n",
    "    else\n",
    "        q = plot!(temp_df.k, temp_df.SD_Valid_MSE, label = \"γ = $( γ_vals[i])\", linecolor = colors[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "plot(p, q, layout = (2,1), size = (700, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we first notice that at $\\gamma = 0.005$, we get the best mean validation score with a low # of features with the lowest sd of validatior performance\n",
    "\n",
    "Holding $\\gamma = 0.005$ constant, we zoom on in $k \\in [15, 70]$, where we see performance start to plateau, and we conduct the fine parameter search within this range. We also conduct a fine search near $\\gamma = 0.005$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals_fine = 5:1:70;\n",
    "γ_vals_fine = [0.0025, 0.00375, 0.005, 0.00625, 0.0075] \n",
    "folds_fine = 15;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fine_grid_df, fine_detailed_results, best_k = sparsity_cross_validation(k_vals_fine, γ_vals_fine, folds_fine, cv_X_f2, cv_y)\n",
    "fine_grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Plotting Fine Grid Results, Option 1\n",
    "###\n",
    "\n",
    "n = length(γ_vals_fine)\n",
    "colors = reshape( range(colorant\"lightgray\", stop=colorant\"darkblue\",length=n), 1, n );\n",
    "p = plot(xlabel = \"Sparsity (k)\", ylabel  = \"Mean, Validation r²\", legend = :outerright, ylim = [0,1], title = \"Fine Search Results\")\n",
    "\n",
    "\n",
    "for i = 1:length(γ_vals_fine)\n",
    "    temp_df = filter(row -> row.γ == γ_vals_fine[i], fine_grid_df)\n",
    "    if  γ_vals_fine[i] == 0.0075\n",
    "        p = plot!(temp_df.k, temp_df.Avg_Valid_MSE, label = \"γ = $( γ_vals_fine[i])\", linecolor = :red)\n",
    "    else\n",
    "        p = plot!(temp_df.k, temp_df.Avg_Valid_MSE, label = \"γ = $( γ_vals_fine[i])\", linecolor = colors[i])\n",
    "    end\n",
    "        \n",
    "end\n",
    "\n",
    "q = plot(xlabel = \"Sparsity (k)\", ylabel  = \"SD, Validation r²\", legend = :outerright, ylim = [0, .4])\n",
    "for i = 1:length(γ_vals_fine)\n",
    "    temp_df = filter(row -> row.γ == γ_vals_fine[i], fine_grid_df)\n",
    "    if  γ_vals_fine[i] == 0.0075\n",
    "        q = plot!(temp_df.k, temp_df.SD_Valid_MSE, label = \"γ = $( γ_vals_fine[i])\", linecolor = :red)\n",
    "    else\n",
    "        q = plot!(temp_df.k, temp_df.SD_Valid_MSE, label = \"γ = $( γ_vals_fine[i])\", linecolor = colors[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "plot(p, q, layout = (2,1), size = (700, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Picking final parameters\n",
    "###\n",
    "\n",
    "best_row = filter(row -> row.Avg_Valid_MSE == maximum(fine_grid_df.Avg_Valid_MSE), fine_grid_df)\n",
    "\n",
    "best_row.Avg_Valid_MSE\n",
    "\n",
    "candidate_models = filter(row -> row.Avg_Valid_MSE >=  0.90* maximum(fine_grid_df.Avg_Valid_MSE), fine_grid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick model with $k=14$ and $\\gamma = 0.0075$. This particular configuration seems to have good performance and lower SD than some of its neighbors and it is more parsimonious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train final learner with selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr = IAI.OptimalFeatureSelectionRegressor(sparsity = 14, gamma = 0.0075)\n",
    "IAI.fit!(lnr, get_ready_X(cv_X_f2), get_log_y(cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_model(lnr, cv_X, cv_y, test_X, test_y)\n",
    "    ### Plot training and test results, along with r2 value\n",
    "    \n",
    "    predict_y_cv = IAI.predict(lnr, get_ready_X(cv_X))\n",
    "    predict_y_test = IAI.predict(lnr, get_ready_X(test_X))\n",
    "    \n",
    "    cv_full = deepcopy(cv_X)\n",
    "    cv_full.real_y = get_log_y(cv_y)\n",
    "    cv_full.predict_y = predict_y_cv\n",
    "    \n",
    "    test_full = deepcopy(test_X)\n",
    "    test_full.real_y = get_log_y(test_y)\n",
    "    test_full.predict_y = predict_y_test\n",
    "    \n",
    "    subplots = []\n",
    "\n",
    "    #Overall\n",
    "    r2 = round(get_r2(cv_full.real_y, cv_full.predict_y), digits=2)\n",
    "    p = Plots.plot(cv_full.real_y, cv_full.real_y, label=\"y=x\", xlabel=\"Actual Log₁₀(Fold Change)\", ylabel=\"Predicted Log₁₀(Fold Change)\", title = \"LL-37 Cluster, training set\")\n",
    "    p = Plots.scatter!(cv_full.real_y, cv_full.predict_y, label=\"r² = $r2\", legend=:outerbottom, markeralpha=0.3)\n",
    "    push!(subplots, p)\n",
    "    \n",
    "        \n",
    "    #Overall test\n",
    "    r2 = round(get_r2(test_full.real_y, test_full.predict_y), digits=2)\n",
    "    p = Plots.plot(test_full.real_y, test_full.real_y, label=\"y=x\", xlabel=\"Actual Log₁₀(Fold Change)\", ylabel=\"Predicted Log₁₀(Fold Change)\", title = \"LL-37 Cluster, test set\")\n",
    "    p = Plots.scatter!(test_full.real_y, test_full.predict_y, label=\"r² = $r2\", legend=:outerbottom,markeralpha=0.3)\n",
    "    push!(subplots, p)\n",
    "    \n",
    "    Plots.plot(subplots[1], subplots[2], layout=(1,2))\n",
    "    \n",
    "end\n",
    "\n",
    "evaluate_model(lnr, cv_X, cv_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test generalizability of model on other clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.Actual_LFC = get_log_y(Y_full)\n",
    "df_full.Predicted_LFC = IAI.predict(lnr, get_ready_X(X_full))\n",
    "\n",
    "#summarize into table\n",
    "\n",
    "\n",
    "cluster_df = combine(groupby(df_full, :Adj_Cluster), \n",
    "        nrow => :n, \n",
    "        :FoldChange => maximum => :Max_Cluster_FoldChange,\n",
    "        [:Actual_LFC, :Predicted_LFC] => ((a,p) -> get_r2(a,p)) => :r2\n",
    ");\n",
    "\n",
    "\n",
    "sort(cluster_df, :r2, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_importance = IAI.variable_importance(lnr)\n",
    "plot(variable_importance.Importance[1:20], size=(700, 200), legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save relevant outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = \"Results_SparseLinearReg_20210319/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# FEATURES REMOVED\n",
    "###\n",
    "CSV.write(store_path*\"feature_selection_df.tsv\", dropped_columns_hist, delim=\"\\t\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# COARSE SEARCH RESULTS\n",
    "###\n",
    "grid_df_output = rename(grid_df, :γ => :gamma)\n",
    "\n",
    "CSV.write(store_path*\"coarse_search_results_data.tsv\", grid_df_output, delim=\"\\t\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# FINE SEARCH RESULTS\n",
    "###\n",
    "\n",
    "fine_grid_df_output = rename(fine_grid_df, :γ => :gamma)\n",
    "fine_grid_df_output\n",
    "\n",
    "CSV.write(store_path*\"fine_search_results_data.tsv\", fine_grid_df_output, delim=\"\\t\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# PREDICTIONS FOR ALL CLUSTERS\n",
    "###\n",
    "# select!(cluster_df, Not(:r))\n",
    "\n",
    "CSV.write(store_path*\"results_by_cluster.tsv\", cluster_df, delim=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# PREDICTIONS FOR ALL AMPs\n",
    "###\n",
    "\n",
    "df_full_output = select(df_full, [:Sequence, :Adj_Cluster, :FoldChange, :Actual_LFC, :Predicted_LFC])\n",
    "\n",
    "CSV.write(store_path*\"predictions_all_AMPs.tsv\", df_full_output, delim=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# PREDICTIONS FOR LL37-like AMPS\n",
    "###\n",
    "\n",
    "cv_X, cv_y, test_X, test_y\n",
    "\n",
    "cv_LL37_full = deepcopy(cv_X)\n",
    "cv_LL37_full.FoldChange = cv_y\n",
    "cv_LL37_full.Actual_LFC = get_log_y(cv_y)\n",
    "cv_LL37_full.Predicted_LFC = IAI.predict(lnr, get_ready_X(cv_X))\n",
    "cv_LL37_full[!, :DataSet] .= \"Train\"\n",
    "\n",
    "test_LL37_full = deepcopy(test_X)\n",
    "test_LL37_full.FoldChange = test_y\n",
    "test_LL37_full.Actual_LFC = get_log_y(test_y)\n",
    "test_LL37_full.Predicted_LFC = IAI.predict(lnr, get_ready_X(test_X))\n",
    "test_LL37_full[!, :DataSet] .= \"Test\"\n",
    "\n",
    "\n",
    "LL37_full_df = vcat(cv_LL37_full, test_LL37_full)\n",
    "size(LL37_full_df)\n",
    "\n",
    "LL37_full_df_output = select(LL37_full_df, [:Sequence, :Adj_Cluster, :FoldChange, :Actual_LFC, :Predicted_LFC, :DataSet])\n",
    "\n",
    "CSV.write(store_path*\"predictions_LL37_AMPs.tsv\", LL37_full_df_output, delim=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# FEATURE IMPORTANCES FINAL MODEL\n",
    "###\n",
    "variable_importance\n",
    "CSV.write(store_path*\"feature_importance_final_model.tsv\", variable_importance, delim=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Store plots for each cluster\n",
    "###\n",
    "\n",
    "cluster_list = unique(df_full.Adj_Cluster)\n",
    "\n",
    "for i = 1:length(cluster_list)\n",
    "    temp_df = filter(row -> row.Adj_Cluster == cluster_list[i], df_full)\n",
    "    \n",
    "    r2 = round(get_r2(temp_df.Actual_LFC, temp_df.Predicted_LFC), digits=2)\n",
    "    p = Plots.plot(temp_df.Actual_LFC, temp_df.Actual_LFC, label=\"y=x\", xlabel=\"Actual Log₁₀(Fold Change)\", ylabel=\"Predicted Log₁₀(Fold Change)\", title = \" Cluster $(cluster_list[i])\")\n",
    "    p = Plots.scatter!(temp_df.Actual_LFC, temp_df.Predicted_LFC, label=\"r² = $r2\", legend=:outerbottom,markeralpha=0.3)\n",
    "    png(store_path*\"cluster_plots/cluster_$(cluster_list[i])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Save Model\n",
    "###\n",
    "\n",
    "@save \"final_model.jld2\" lnr\n",
    "\n",
    "IAI.write_json(\"final_model_json.json\", lnr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
